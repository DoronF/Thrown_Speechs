{
  "hash": "d5123c03feb89a4a2f3595d2bd81e036",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"LDA Topic Extraction and Analysis\"\nauthor: \"Doron Feingold\"\ndate: \"today\"\nformat: \n  html:\n    toc: true\n    toc-location: right\n    self-contained: true\n    theme: cosmo\n    code-overflow: wrap\nexecute:\n  echo: false\n---\n\n## Overview\nLDA (Latent Dirichlet Allocation) is a probabilistic topic modeling technique that discovers hidden thematic structures in large collections of text documents. It assumes each document is a mixture of topics, and each topic is characterized by a distribution of words, allowing it to automatically identify and extract meaningful topics from unstructured text data. The model requires us to select the number of topics beforehand. Since it is unknown to us which number of topics is right, we train several LDA models with different numbers of topics (`k`). We then evaluate, compare and rank all the models', topic quality and temporal balance. Finally we choose which number of topics is best overall. \n\n## Setup\nWe load packages, most notably we load `topicmodels` for training the LDA models.\nwe also load our `project_stopwords` and `intrusion_regex` (boilerplate), we established in the previous step.\n\n::: {.cell}\n\n```{.r .cell-code}\n# Seed\nset.seed(1867)\n\n# Load all necessary libraries\nlibrary(dplyr)\nlibrary(tidytext)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(topicmodels)\nlibrary(purrr)\nlibrary(patchwork)\nlibrary(tictoc)\nlibrary(Matrix)\nlibrary(cowplot)\n\n# Load project-specific functions and data\nsource(\"R/functions.R\")\nclean_corpus <- readr::read_csv(\n  \"output/segmentation/llm_clean_segmented_corpus.csv\"\n)\nintrusion_regex <- readRDS(\"output/boilerplate/intrusion_regex.rds\")\nproject_stopwords <- get_project_stopwords()\n\nk_values <- c(4, 6, 8, 10, 12)\n```\n:::\n\n\n## Pre-Processing\n\nWe prepare the text and create a single Document-Term Matrix (DTM) using `tidytext`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Prepare tidy word list\nlemmatized_policy_words <- clean_corpus %>%\n  mutate(\n    policy_content = str_remove_all(\n      policy_content,\n      regex(intrusion_regex, ignore_case = TRUE)\n    )\n  ) %>%\n  unnest_tokens(word, policy_content) %>%\n  anti_join(project_stopwords, by = \"word\") %>%\n  mutate(lemma = textstem::lemmatize_words(word))\n\n# Create the DTM for the topicmodels package\ndtm_tm <- lemmatized_policy_words %>%\n  count(filename, lemma, sort = TRUE) %>%\n  cast_dtm(filename, lemma, n)\n```\n:::\n\n\n## Iterative LDA Topic Modeling\n\nWe now train a separate LDA model for each `k` value `k_values <- c(4, 6, 8, 10, 12)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntic(\"Total training time for all models\")\nlda_models <- k_values %>%\n  purrr::map(function(k) {\n    LDA(dtm_tm, k = k, control = list(seed = 1867))\n  })\ntoc()\n\nsaveRDS(lda_models, \"output/models/lda_models.rds\")\n```\n:::\n\n\n## Model Results and Analysis\nTo evaluate the results we review the following:  \n\n* **Topic Distribution by Era**: Are the topics evenly distributed across the eras?\n* **Topic Prominence Over Time**: Do the topics show clear prominence trends? \n* **Topic Quality**: Dominance (how often a topic is the primary theme of a speech) vs. Exclusivity (uniqueness). \n\n\n::: {.cell}\n\n:::\n\n\n\n::: {.cell}\n\n:::\n\n\n### **Topic Distribution by Era**\nWe can see how many topics peaked in each era: \n\n* **Pre-War** 1867 - 1940\n* **Mid-Century** 1940 - 1980\n* **Modern Era** 1980 - 2025\n\n we want to see even distribution more or less so that topics are not concentrated in one time period. \n\n#### **Era Distribution Grid**\n\n::: {.cell}\n::: {.cell-output-display}\n![](output/figures/era_plot-1.png){width=960}\n:::\n:::\n\n\n#### **Proportional Distribution**\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| Pre-War %| Mid-Century %| Modern Era %|\n|-------:|---------:|-------------:|------------:|\n|       4|      25.0|          25.0|         50.0|\n|       6|      16.7|          50.0|         33.3|\n|       8|      25.0|          37.5|         37.5|\n|      10|      20.0|          30.0|         50.0|\n|      12|      16.7|          33.3|         50.0|\n\n\n:::\n:::\n\n\n#### **Era Distribution Evenness Analysis**\nLower `std_dev`, `range_spread`, and `coeff_var` = more even distribution\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| Pre-War| Mid-Century| Modern Era| std_dev| range_spread| coeff_var| evenness_rank|\n|-------:|-------:|-----------:|----------:|-------:|------------:|---------:|-------------:|\n|       8|       2|           3|          3|   0.072|        0.125|     0.217|           1.0|\n|       4|       1|           1|          2|   0.144|        0.250|     0.433|           2.0|\n|      10|       2|           3|          5|   0.153|        0.300|     0.458|           3.0|\n|       6|       1|           3|          2|   0.167|        0.333|     0.500|           4.5|\n|      12|       2|           4|          6|   0.167|        0.333|     0.500|           4.5|\n\n\n:::\n:::\n\n\nMost even distribution: k = **8**\n\n***\n\n### **Topic Prominence Over Time**\n\nThis plot compares the topic prominence line charts for each `k` value. A good model should show distinct and interpretable trend lines.\n\n#### **Time Series Plot**\n\n::: {.cell}\n::: {.cell-output-display}\n![](output/figures/time_series_grid-1.png){width=960}\n:::\n:::\n\n\n#### **Sample of yearly prominence data**\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| year| topic| avg_gamma| k_value|\n|----:|-----:|---------:|-------:|\n| 1867|     1| 0.0002554|       4|\n| 1867|     2| 0.0002554|       4|\n| 1867|     3| 0.9992339|       4|\n| 1867|     4| 0.0002554|       4|\n| 1869|     1| 0.0003494|       4|\n| 1869|     2| 0.0003494|       4|\n\n\n:::\n:::\n\n\n#### **Variance-based Analysis**\n\n- Higher variance = more dynamic topics (some very prominent, some barely there)  \n- Lower variance = more balanced prominence across topics\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| avg_variance| max_variance| min_variance| high_variance_topics|\n|-------:|------------:|------------:|------------:|--------------------:|\n|      12|       0.0548|       0.2074|       0.0123|                   12|\n|      10|       0.0621|       0.2059|       0.0200|                   10|\n|       8|       0.0778|       0.2070|       0.0401|                    8|\n|       6|       0.0981|       0.2050|       0.0390|                    6|\n|       4|       0.1400|       0.2007|       0.1037|                    4|\n\n\n:::\n:::\n\n\nVariance Analysis (lower `avg_variance` = more stable topics)\n\n#### **\"Dead Topics\" Analysis**\nCount topics that never achieve meaningful prominence\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| total_topics| dead_topics| weak_topics| moderate_topics| strong_topics| dead_topic_pct| weak_topic_pct|\n|-------:|------------:|-----------:|-----------:|---------------:|-------------:|--------------:|--------------:|\n|       4|            4|           0|           0|               0|             4|              0|              0|\n|       6|            6|           0|           0|               0|             6|              0|              0|\n|       8|            8|           0|           0|               0|             8|              0|              0|\n|      10|           10|           0|           0|               0|            10|              0|              0|\n|      12|           12|           0|           0|               0|            12|              0|              0|\n\n\n:::\n:::\n\n\nThere are no \"dead topics\".\n\n#### **Prominence Range Analysis**\nLook at the spread between most and least prominent topics each year.\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| avg_range| avg_dominant_strength| avg_weakest_strength| max_range|\n|-------:|---------:|---------------------:|--------------------:|---------:|\n|       4|    0.8964|                0.8965|                1e-04|    0.9999|\n|      12|    0.8737|                0.8737|                0e+00|    0.9999|\n|       8|    0.8709|                0.8710|                1e-04|    0.9999|\n|       6|    0.8700|                0.8701|                1e-04|    0.9999|\n|      10|    0.8512|                0.8513|                0e+00|    0.9999|\n\n\n:::\n:::\n\n\nRange Analysis (higher `avg_range` might = better topic separation)\n\n#### **Combined Ranking**\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| variance_rank| dead_rank| range_rank| combined_score| overall_rank|\n|-------:|-------------:|---------:|----------:|--------------:|------------:|\n|      12|             1|         3|          2|              6|          1.0|\n|       4|             5|         3|          1|              9|          2.5|\n|       8|             3|         3|          3|              9|          2.5|\n|      10|             2|         3|          5|             10|          4.0|\n|       6|             4|         3|          4|             11|          5.0|\n\n\n:::\n:::\n\n\n**Combined Ranking** (lower overall rank = better model): \n* Variance rank: 1 = most stable topics  \n* Dead rank: 1 = fewest useless topics   \n* Range rank: 1 = best topic separation\n\n\n---\n\n\n### Topic Quality: Dominance vs. Exclusivity\nThis plot compares topic dominance (how often a topic is the primary theme of a speech) with exclusivity. This helps identify which topics are both important and unique.\n\n#### **Dominance Plot**\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](output/figures/dominance_grid-1.png){width=960}\n:::\n:::\n\n\n● Pre-War (pre-1940) ▲ Mid-Century (1940-1980) ■ Modern Era (1980+)\n\n#### **Sample of topic metrics data:**\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| topic| exclusivity| dominance_count|era         |\n|-------:|-----:|-----------:|---------------:|:-----------|\n|       4|     1|          12|              52|Mid-Century |\n|       4|     2|          16|              19|Modern Era  |\n|       4|     3|          17|              59|Pre-War     |\n|       4|     4|           9|              22|Modern Era  |\n|       6|     1|          11|              32|Mid-Century |\n|       6|     2|           7|              13|Modern Era  |\n\n\n:::\n:::\n\n\n#### **Dominance + Exclusivity Quality Score**\nModel Quality Summary (higher avg_quality_score = better):\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| avg_quality_score| avg_weighted_score| high_quality_topics| balanced_topics| low_quality_topics| quality_std| avg_exclusivity| avg_dominance|\n|-------:|-----------------:|------------------:|-------------------:|---------------:|------------------:|-----------:|---------------:|-------------:|\n|       4|             0.696|              0.710|                   2|               1|                  0|       0.253|            13.5|          38.0|\n|       6|             0.438|              0.446|                   1|               1|                  3|       0.224|             9.2|          25.3|\n|       8|             0.347|              0.359|                   1|               0|                  5|       0.222|             8.1|          19.0|\n|      10|             0.236|              0.239|                   0|               1|                  8|       0.202|             5.8|          15.2|\n|      12|             0.209|              0.216|                   1|               0|                  9|       0.196|             5.7|          12.7|\n\n\n:::\n:::\n\n\n#### **Principal Component Analysis on Dominance + Exclusivity**\nThe PCA reveals that dominance and exclusivity are moderately correlated, with 70% of the variance captured by the first principal component. This suggests these two quality metrics largely move together - topics that dominate more speeches tend to also be more exclusive (have unique vocabulary).\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nImportance of components:\n                          PC1    PC2\nStandard deviation     1.3076 0.5387\nProportion of Variance 0.8549 0.1451\nCumulative Proportion  0.8549 1.0000\n```\n\n\n:::\n:::\n\n\nPCA Model Summary (higher avg_pc1 = better overall quality):\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| avg_pc1| avg_pc2| pc1_std|\n|-------:|-------:|-------:|-------:|\n|      12|   0.629|   0.108|   1.014|\n|      10|   0.498|   0.186|   1.047|\n|       8|  -0.126|  -0.126|   1.120|\n|       6|  -0.596|  -0.075|   1.126|\n|       4|  -1.989|  -0.425|   1.298|\n\n\n:::\n:::\n\n\nVariable Contributions to PC1:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n    exclusivity dominance_count \n         -0.707          -0.707 \n```\n\n\n:::\n:::\n\n\nCorrelation between Exclusivity and Dominance: **0.7098022**\n\n#### **Topic Efficiency Analysis**\nTopic Efficiency Analysis (higher efficiency_rate = more good topics per k):\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| total_topics| high_quality_count| efficiency_rate| avg_exclusivity_per_topic| avg_dominance_per_topic| exclusivity_per_k| dominance_per_k|\n|-------:|------------:|------------------:|---------------:|-------------------------:|-----------------------:|-----------------:|---------------:|\n|       4|            4|                  3|            75.0|                     13.50|                   38.00|             13.50|           38.00|\n|       6|            6|                  1|            16.7|                      9.17|                   25.33|              9.17|           25.33|\n|       8|            8|                  1|            12.5|                      8.12|                   19.00|              8.12|           19.00|\n|      10|           10|                  1|            10.0|                      5.80|                   15.20|              5.80|           15.20|\n|      12|           12|                  1|             8.3|                      5.67|                   12.67|              5.67|           12.67|\n\n\n:::\n:::\n\n\n#### **Final Topic Quality Ranking**\n\nFinal Ranking (lower final_rank = better dominance + exclusivity combination):\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n| k_value| quality_rank| pca_rank| efficiency_rank| combined_score| final_rank|\n|-------:|------------:|--------:|---------------:|--------------:|----------:|\n|       4|            1|        5|               1|       2.333333|          1|\n|       6|            2|        4|               2|       2.666667|          1|\n|       8|            3|        3|               3|       3.000000|          1|\n|      10|            4|        2|               4|       3.333333|          1|\n|      12|            5|        1|               5|       3.666667|          1|\n\n\n:::\n:::\n\n\n## Conclusion\n\nThe analysis reveals a clear trade-off between topic quality and temporal balance.\n\n- **For Highest Topic Quality:** The **k=4** model is the undisputed winner. It produces the most distinct, dominant, and efficient topics. If the goal is to identify the strongest, most interpretable themes in the corpus, **k=4** is the best choice.\n    \n- **For Best Temporal Balance:** The **k=8** model offers the most even distribution of topics across historical eras (Pre-War, Mid-Century, Modern Era) and demonstrates high stability in topic prominence over time. If the goal is to analyze how different themes evolve and ensure all periods are represented, **k=8** is the superior option.\n\nSince they have different things to tell us about the texts, we choose **both**.\n\n**Next Step:** [LLM Interpretation of Topic Models →](06_Topics_Interpretation.qmd)",
    "supporting": [
      "05_Topics_Extraction_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}